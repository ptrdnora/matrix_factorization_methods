{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUNY MSDS DATA643 - Recommender System\n",
    "\n",
    "---\n",
    "\n",
    "### Rose Koh\n",
    "### 06/22/2018\n",
    "---\n",
    "\n",
    "## Matrix factorization methods\n",
    "\n",
    "* Implement a matrix factorization method—such as singular value decomposition (SVD) or,\n",
    "* Alternating Least Squares (ALS)—in the context of a recommender system.\n",
    "\n",
    "You may approach this assignment in a number of ways. You are welcome to start with an existing recommender system written by yourself or someone else.  \n",
    "\n",
    "SVD can be thought of as a pre-processing step for feature engineering. You might easily start with thousands or millions of items, and use SVD to create a much smaller set of “k” items (e.g. 20 or 70)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project 3\n",
    "* SVD from project 2\n",
    "* ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description\n",
    "\n",
    "This dataset describes 5-star rating and free-text tagging activity from [MovieLens](http://movielens.org), a movie recommendation service. It contains 100004 ratings and 1296 tag applications across 9125 movies. These data were created by 671 users between January 09, 1995 and October 16, 2016. This dataset was generated on October 17, 2016.\n",
    "\n",
    "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
    "\n",
    "For this project, we are going to use the subset of the data.\n",
    "The data contained in the files as follows: \n",
    "\n",
    "* u.data\n",
    "* u.item\n",
    "* Movie_Id_Titles\n",
    "\n",
    "This and other GroupLens data sets are publicly available for download at <http://grouplens.org/datasets/>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>880473582</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>891271545</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>888552084</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>879362124</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp             title\n",
       "0        0       50       5  881250949  Star Wars (1977)\n",
       "1      290       50       5  880473582  Star Wars (1977)\n",
       "2       79       50       4  891271545  Star Wars (1977)\n",
       "3        2       50       5  888552084  Star Wars (1977)\n",
       "4        8       50       5  879362124  Star Wars (1977)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "# user data\n",
    "df = pd.read_csv('data/u.data', sep='\\t', names=column_names)\n",
    "# movie title data\n",
    "movie_titles = pd.read_csv(\"data/Movie_Id_Titles\")\n",
    "\n",
    "# merge\n",
    "df = pd.merge(df,movie_titles,on='item_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_to_movie = {}\n",
    "# item(movie) data\n",
    "with open('data/u.item', encoding = \"ISO-8859-1\") as f:\n",
    "    for line in f.readlines():\n",
    "        info = line.split('|')\n",
    "        idx_to_movie[int(info[0])-1] = info[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 944 | Number of movies = 1682\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn import cross_validation as cv\n",
    "\n",
    "# Split Data\n",
    "train_data, test_data = cv.train_test_split(df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create two user-item matrices, one for training and another for testing\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1] - 1, line[2] - 1] = line[3]\n",
    "\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1] - 1, line[2] - 1] = line[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function set\n",
    "\n",
    "* rmse computation\n",
    "* predict: user-user and item-item similarity\n",
    "* top k movie names by user mapping function\n",
    "* predict ratings using dot product of the latent features for users and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "def rmse(pred, actual):\n",
    "    # Root Mean Squared Error. We will conside only non-zero ratings\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(pred, actual))\n",
    "\n",
    "def predict(ratings, similarity, type='user', epsilon=1e20):\n",
    "    # Predict function to find user-user similarity and item-item similarity.\n",
    "    # User bias is removed by adjusting the mean user bias before predicting ratings\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "    # You use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred\n",
    "\n",
    "def top_k_movies_by_user(pred, mapper, user_idx, k=6):\n",
    "    # Find the top-k movie names based on the ordered ratings\n",
    "    return [mapper[x] for x in\n",
    "            np.argsort(pred[user_idx, np.where(train_data_matrix[user_idx, :] == 0)[0]])[:-k - 1:-1]]\n",
    "\n",
    "def predictionSGD(P, Q):\n",
    "    # Predict the ratings using dot product of the latent features for users and items\n",
    "    return np.dot(P.T, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory based Collaborative Filtering\n",
    "* user-item filtering: Users who are similar to you also liked ...\n",
    "* item-item filtering: Users who liked this item also liked..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the cosine distance and 1-cosine distance yields cosine similarity.\n",
    "# epsilon is used to handle the divide by zero scenarios\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "epsilon = 1e-9\n",
    "\n",
    "user_similarity = (1 - pairwise_distances(train_data_matrix, metric='cosine')) + epsilon\n",
    "item_similarity = (1 - pairwise_distances(train_data_matrix.T, metric='cosine')) + epsilon\n",
    "\n",
    "user_idx = 23\n",
    "\n",
    "pred = predict(train_data_matrix, user_similarity, type='user')\n",
    "\n",
    "user_base_train_rmse = rmse(pred, train_data_matrix)\n",
    "user_base_test_rmse = rmse(pred, test_data_matrix)\n",
    "\n",
    "trainRMSE = []\n",
    "testRMSE = []\n",
    "\n",
    "trainRMSE.append(user_base_train_rmse)\n",
    "testRMSE.append(user_base_test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE on train data: 2.8973011016563786\n",
      "User-based CF RMSE on test data: 2.9567967443898864\n",
      "\n",
      "Movies recommended to user 23 are:\n",
      "['Disclosure (1994)', \"Weekend at Bernie's (1989)\", \"Monty Python's Life of Brian (1979)\", 'Truth About Cats & Dogs, The (1996)', 'Toy Story (1995)', 'I.Q. (1994)']\n",
      "\n",
      "Item-based CF RMSE on train data: 3.0969544116017405\n",
      "Item-based CF RMSE on test data: 3.1634832502337686\n",
      "\n",
      "Movies recommended to user 23 are:\n",
      "['Man from Down Under, The (1943)', 'Butterfly Kiss (1995)', 'Delta of Venus (1994)', 'Paris, Texas (1984)', 'Twelfth Night (1996)', \"C'est arrivé près de chez vous (1992)\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('User-based CF RMSE on train data: ' + str(user_base_train_rmse))\n",
    "print('User-based CF RMSE on test data: ' + str(user_base_test_rmse) + \"\\n\")\n",
    "print(\"Movies recommended to user \" + str(user_idx) + \" are:\")\n",
    "nearestMovies = top_k_movies_by_user(pred, idx_to_movie, user_idx)\n",
    "print(str(nearestMovies) + \"\\n\")\n",
    "\n",
    "pred = predict(train_data_matrix, item_similarity, type='item')\n",
    "\n",
    "item_base_train_rmse = rmse(pred, train_data_matrix)\n",
    "item_base_test_rmse = rmse(pred, test_data_matrix)\n",
    "trainRMSE.append(item_base_train_rmse)\n",
    "testRMSE.append(item_base_test_rmse)\n",
    "\n",
    "print('Item-based CF RMSE on train data: ' + str(item_base_train_rmse))\n",
    "print('Item-based CF RMSE on test data: ' + str(item_base_test_rmse) + \"\\n\")\n",
    "print(\"Movies recommended to user \" + str(user_idx) + \" are:\")\n",
    "nearestMovies = top_k_movies_by_user(pred, idx_to_movie, user_idx)\n",
    "print(str(nearestMovies) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "\n",
    "A well-known matrix factorization method is **Singular value decomposition (SVD)**. Collaborative Filtering can be formulated by approximating a matrix `X` by using singular value decomposition. The winning team at the Netflix Prize competition used SVD matrix factorization models to produce product recommendations, for more information I recommend to read articles: [Netflix Recommendations: Beyond the 5 stars](http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html) and [Netflix Prize and SVD](http://buzzard.ups.edu/courses/2014spring/420projects/math420-UPS-spring-2014-gower-netflix-SVD.pdf).\n",
    "The general equation can be expressed as follows:\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?X=USV^T\" title=\"X=USV^T\" />\n",
    "\n",
    "\n",
    "Given `m x n` matrix `X`:\n",
    "* *`U`* is an *`(m x r)`* orthogonal matrix\n",
    "* *`S`* is an *`(r x r)`* diagonal matrix with non-negative real numbers on the diagonal\n",
    "* *V^T* is an *`(r x n)`* orthogonal matrix\n",
    "\n",
    "Elements on the diagnoal in `S` are known as *singular values of `X`*. \n",
    "\n",
    "\n",
    "Matrix *`X`* can be factorized to *`U`*, *`S`* and *`V`*. The *`U`* matrix represents the feature vectors corresponding to the users in the hidden feature space and the *`V`* matrix represents the feature vectors corresponding to the items in the hidden feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-based CF MSE on train data: 2.2711166477386304\n",
      "Model-based CF MSE on test data: 2.797821218930048\n",
      "\n",
      "Movies recommended to user 23 are:\n",
      "['I.Q. (1994)', 'From Dusk Till Dawn (1996)', 'Braveheart (1995)', 'Gigi (1958)', 'Toy Story (1995)', 'Fish Called Wanda, A (1988)']\n",
      "\n",
      "   Actual Rating  Predicted Rating\n",
      "0            4.0          3.412068\n",
      "1            5.0          1.744381\n",
      "2            5.0          4.360307\n",
      "3            5.0          2.174179\n",
      "4            5.0          3.334611\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    " \n",
    "#get SVD components from train matrix. Choose k.\n",
    "u, s, vt = svds(train_data_matrix, k = 30)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    " \n",
    "model_base_train_rmse = rmse(X_pred, train_data_matrix)\n",
    "model_base_test_rmse = rmse(X_pred, test_data_matrix)\n",
    "trainRMSE.append(model_base_train_rmse)\n",
    "testRMSE.append(model_base_test_rmse)\n",
    " \n",
    "print('Model-based CF MSE on train data: ' + str(model_base_train_rmse))\n",
    "print('Model-based CF MSE on test data: ' + str(model_base_test_rmse) + \"\\n\")\n",
    " \n",
    "print(\"Movies recommended to user \" + str(user_idx) + \" are:\")\n",
    "nearestMovies = top_k_movies_by_user(X_pred, idx_to_movie, user_idx)\n",
    "print(str(nearestMovies) + \"\\n\")\n",
    " \n",
    "# Compare true ratings of user with predictions\n",
    "ratings = pd.DataFrame(columns = (\"Actual Rating\",\"Predicted Rating\"))\n",
    "ratings[\"Actual Rating\"] = train_data_matrix[user_idx,np.where(train_data_matrix[user_idx, :] > 0)[0]][0:5]\n",
    "ratings[\"Predicted Rating\"] = X_pred[user_idx,np.where(train_data_matrix[user_idx, :] > 0)[0]][0:5]\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * SVD does not seem to perform any better than memory based model.\n",
    " * SVD approach isn't optimal for dataset with missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of MovieLens100K is 93.7%\n"
     ]
    }
   ],
   "source": [
    "sparsity=round(1.0-len(df)/float(n_users*n_items),3)\n",
    "print(('The sparsity level of MovieLens100K is ') +  str(sparsity*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS\n",
    "\n",
    "### Notations\n",
    "* Let $n_u$ and $n_p$ be the number of users and products.\n",
    "* Let $R \\in \\mathbb{R}^{n_u \\times n_p}$ be the matrix of ratings, where entry $r_{ij}$, $1 \\le i \\le n_u$ and $1 \\le j \\le n_p$, is the rating of user $i$ for product $j$. Entries $r_{ij}$ contain many missing values.\n",
    "* Let $w_{i,j}$ be an indicator of the existence of a rating for product $j$ by user $i$, i.e., $w_{i,j}=1$ if the rating $(i,j)$ exists, and $w_{i,j}=0$ otherwise.\n",
    "* Let $k$ be the rank of the matrix factorisation.\n",
    "* Let $U \\in \\mathbb{R}^{n_u \\times n_k}$ be the user matrix, and $P \\in \\mathbb{R}^{n_p \\times n_k}$ be the products (item) matrix \n",
    "* Let $U_i$ be the $i-$th row of $U$, and $P_j$ be the $j-$th row of $P$.\n",
    "\n",
    "![alt text](matprod.jpg \"Ratings matrix factorisation\")\n",
    "\n",
    "* Let $\\hat{R}$ be the predicted rating matrix, where all missing values are predicted on the basis of known user ratings. \n",
    "* The optimisation function is expressed as \n",
    "\n",
    "$$\n",
    "J(U,P)=||(R-UP^T)||_2\n",
    "$$\n",
    "\n",
    "* and predictions $\\hat{R}$ given by \n",
    "\n",
    "$$\n",
    "\\hat{R}=UP^T\n",
    "$$\n",
    "\n",
    "### Alternating Least Squares\n",
    "\n",
    "* Note that since both $U$ and $P$ are unknown, the optimisation function $J(U,P)$ is non convex.\n",
    "* However, if we fix $P$ and optimise for $U$ alone, the problem is simply reduced to the problem of linear regression, and can be solved using Ordinary Least Square (OLS):\n",
    "\n",
    "$$\n",
    "U^T=(P^TP)^{-1}P^TR^T\n",
    "$$\n",
    "\n",
    "Then, fixing $U$ and optimising for P gives\n",
    "\n",
    "$$\n",
    "P^T=(U^TU)^{-1}U^TR\n",
    "$$\n",
    "\n",
    "\n",
    "* ALS does just that, iteratively optimising $U$ by fixing $P$, and optimising $P$ by fixing $U$. It is guaranteed to converge only to a local minima, which ultimately depends on initial values for $U$ or $P$. \n",
    "\n",
    "* **Missing values**: Since R contains missing values, regression must be computed per user (or product), using only those entries for which the ratings are known ($w_{i,j}=1$). This is done by going though all users (or products):\n",
    "    * For each i, compute $$U^T_i=(\\sum_{j, w_{i,j}=1} P_j^TP_j)^{-1} \\sum_{j, w_{i,j}=1} P_j^Tr_{ij}$$\n",
    "    * For each j, compute $$P^T_j=(\\sum_{i, w_{i,j}=1} U_i^TU_i)^{-1} \\sum_{i, w_{i,j}=1} U_i^Tr_{ij}$$\n",
    "\n",
    "\n",
    "###  ALS algorithm\n",
    "\n",
    "1. Initialize the matrix P by assigning to the first column the average rating for each product, and using small random numbers for the remaining columns.\n",
    "2. Fix P and solve for U_i that minimizes the objective function (RMSE).\n",
    "3. Fix U and solve for P_j that minimizes the objective function similarly.\n",
    "4. Repeat steps 2 and 3 until convergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description\n",
    "\n",
    "For ALS, We are going to try implement pyspark.\n",
    "\n",
    "This dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from [MovieLens](http://movielens.org), a movie recommendation service. It contains 100004 ratings and 1296 tag applications across 9125 movies. These data were created by 671 users between January 09, 1995 and October 16, 2016. This dataset was generated on October 17, 2016.\n",
    "\n",
    "Users were selected at random for inclusion. All selected users had rated at least 20 movies. No demographic information is included. Each user is represented by an id, and no other information is provided.\n",
    "\n",
    "The data are contained in the files as follows: \n",
    "\n",
    "* `links.csv` \n",
    "* `movies.csv` \n",
    "* `ratings.csv`\n",
    "* `tags.csv`\n",
    "\n",
    "More details about the contents and use of all these files follows.\n",
    "\n",
    "This is a *development* dataset. As such, it may change over time and is not an appropriate dataset for shared research results. See available *benchmark* datasets if that is your intent.\n",
    "\n",
    "This and other GroupLens data sets are publicly available for download at <http://grouplens.org/datasets/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load Data with pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define download location\n",
    "import os\n",
    "\n",
    "datasets_path = os.path.join(os.getcwd(), 'data')\n",
    "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Proceed download\n",
    "import urllib\n",
    "\n",
    "small_f = urllib.request.urlretrieve(small_dataset_url, small_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the zip file\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rating_path = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "* ratings.csv: userId, movioeId, rating, timestamp\n",
    "* movies.csv: movieId, title, genres\n",
    "    * genres: Genre1 | Genre2 | Genre3...\n",
    "* tags.csv: userId, movieId, tag, timestamp\n",
    "* links.csv: UserId, movieId, imdbId,tmdbId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rating = pd.read_csv(rating_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100004, 4)\n"
     ]
    }
   ],
   "source": [
    "print(rating.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "np.random.seed(23)\n",
    "i_training = np.random.rand(len(rating)) < 0.8\n",
    "train= rating[i_training].reset_index(drop=True)\n",
    "test= rating[~i_training].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop timestamp\n",
    "rating = rating.drop(\"timestamp\", axis = 1)\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = cv.train_test_split(rating, test_size=0.2)\n",
    "train = train_data.reset_index(drop = True)\n",
    "test = test_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex userId, movieId so the rainge is in the interval [0, n_u-1] and [0, n_p-1]\n",
    "# Keep only those movies and user IDs which are in the training data (no predictions for 'new' users and movies)\n",
    "test = test[test.movieId.isin(train.movieId)]\n",
    "test = test[test.userId.isin(train.userId)].reset_index(drop=True)\n",
    "\n",
    "# remove test dataset user Id and movie Id that is not included in the training set \n",
    "# as we will not approach rating new users/movies\n",
    "# Reindex users and movies so IDs are between 0 and numbers of users/movies\n",
    "userId = train.userId.unique()\n",
    "user_mapping = dict(zip(userId,range(len(userId))))\n",
    "train.userId = train.userId.map(user_mapping)\n",
    "test.userId = test.userId.map(user_mapping)\n",
    "\n",
    "movieId = train.movieId.unique()\n",
    "movie_mapping = dict(zip(movieId,range(len(movieId))))\n",
    "train.movieId = train.movieId.map(movie_mapping)\n",
    "test.movieId = test.movieId.map(movie_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80003, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratings in train\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19261, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratings in test\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of unique users\n",
    "n_u=len(train.userId.unique())\n",
    "n_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8391"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of unique movies\n",
    "n_p=len(train.movieId.unique())\n",
    "n_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       0        0     3.0\n",
       "1       1        1     4.5\n",
       "2       2        2     5.0\n",
       "3       3        3     4.0\n",
       "4       4        4     3.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>619</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>1567</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125</td>\n",
       "      <td>5197</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>296</td>\n",
       "      <td>986</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>267</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0      28      619     3.5\n",
       "1     132     1567     0.5\n",
       "2     125     5197     5.0\n",
       "3     296      986     3.0\n",
       "4      51      267     4.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * ALS - Centralised approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialise k (the ALS rank), and lambda_reg (regularization params)\n",
    "# Initialize the matrix P by assigning to the first column the average rating for each movie, \n",
    "# and using small random numbers for the remaining columns.\n",
    "\n",
    "k = 1\n",
    "\n",
    "np.random.seed(23)\n",
    "P = np.random.rand(n_p,k)\n",
    "\n",
    "average_rating_movie = np.array(train.groupby('movieId').rating.mean())\n",
    "P[:,0] = average_rating_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS function\n",
    "\n",
    "The function aims at computing the OLS for a subset of entries of the rating matrix. \n",
    "\n",
    "* Inputs\n",
    "    * Array of 2 columns: set of indices to keep from rating matrix and corresponding ratings.\n",
    "    * Array: Matrix U or P depending on which matrix is updated. (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OLS(list_id_rating, X, lambda_reg=0.1):\n",
    "    list_id_rating = np.reshape(np.array(list_id_rating),(-1,2))\n",
    "    X = np.array(X)\n",
    "    \n",
    "    #Get the subset of rows from X for which to compute OLS\n",
    "    #Convert indices to int\n",
    "    list_id=[int(elt) for elt in list_id_rating[:,0]]\n",
    "    X_j = X[list_id,:] \n",
    "    \n",
    "    #Compute OLS\n",
    "    k = X_j.shape[1]\n",
    "    XtX = np.dot(np.transpose(X_j),X_j) + lambda_reg * np.identity(k)\n",
    "    XtY = np.dot(np.transpose(X_j),list_id_rating[:,1])\n",
    "    OLS_coef = np.transpose(np.dot(np.linalg.inv(XtX),XtY))\n",
    "    \n",
    "    return OLS_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This takes U and P matrices, and compute the predictions for pairs userId/movieId in rating\n",
    "def get_pred(U,P,rating):\n",
    "    N=rating.shape[0]\n",
    "    predictions=np.zeros(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        predictions[i]=np.sum(np.dot(U[rating.userId[i],:],P[rating.movieId[i],:]))\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n"
     ]
    }
   ],
   "source": [
    "#Number of iterations\n",
    "T = 1\n",
    "\n",
    "for t in range(T):\n",
    "    \n",
    "    print('Iteration: ',t)\n",
    "    \n",
    "    U = np.vstack(train.groupby('userId').\n",
    "                            apply(lambda list_id_rating: OLS(list_id_rating[['movieId','rating']],P)))\n",
    "    \n",
    "    P = np.vstack(train.groupby('movieId').\n",
    "                            apply(lambda list_id_rating: OLS(list_id_rating[['userId','rating']],U)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8090376648900013"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = get_pred(U,P,train)\n",
    "rmse(np.array(train.rating),np.array(train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9074686816484212"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred=get_pred(U,P,test)\n",
    "rmse(np.array(test.rating),np.array(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.983248  ,  4.04853833,  4.00810724,  3.70573411,  2.7067777 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.0\n",
       "1    4.5\n",
       "2    5.0\n",
       "3    4.0\n",
       "4    3.0\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.rating[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * ALS - Map/Reduce approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--conf spark.driver.memory=2g  pyspark-shell\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Start Spark session with local master and 2 cores\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"ALS\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform training and validation in RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number of partitions\n",
    "p = 4\n",
    "\n",
    "train_rdd = sc.parallelize(np.array(train),p)\n",
    "test_rdd = sc.parallelize(np.array(test),p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Same initialisation as centralised ALS\n",
    "k = 1\n",
    "\n",
    "np.random.seed(23)\n",
    "P = np.random.rand(n_p,k)\n",
    "\n",
    "average_rating_movie = np.array(train.groupby('movieId').rating.mean())\n",
    "P[:,0] = average_rating_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Error training set: 0.8090376648900013\n",
      "Error validation set: 0.9074686816484212\n"
     ]
    }
   ],
   "source": [
    "# Adapt the centralized ALS in a Spark Map/Reduce way.\n",
    "\n",
    "T=1\n",
    "\n",
    "for t in range(T):\n",
    "    \n",
    "    print('Iteration: ',t)\n",
    "    \n",
    "    #Grouped by user ID (first column), value is (movieId,rating) (second and third columns)\n",
    "    R1 = train_rdd.map(lambda x: (x[0],[x[1],x[2]])).groupByKey()\n",
    "    \n",
    "    U = np.array(R1.mapValues(lambda list_id_rating:OLS(list(list_id_rating),P)).\n",
    "                    sortByKey().values().collect())\n",
    "    \n",
    "    #Grouped by movie ID (second column), value is (userId,rating) (first and third columns)\n",
    "    R2 = train_rdd.map(lambda x: (x[1],[x[0],x[2]])).groupByKey()\n",
    "    P = np.array(R2.mapValues(lambda list_id_rating:OLS(list(list_id_rating),U)).\n",
    "                    sortByKey().values().collect())\n",
    "    \n",
    "    trian_pred = get_pred(U,P,train)\n",
    "    train_error = rmse(np.array(train.rating),np.array(train_pred))\n",
    "    \n",
    "    print(\"Error training set: \"+str(train_error))\n",
    "    \n",
    "    test_pred = get_pred(U,P,test)\n",
    "    test_error = rmse(np.array(test.rating),np.array(test_pred))\n",
    "    \n",
    "    print(\"Error validation set: \"+str(test_error))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8090376648900013"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train=get_pred(U,P,train)\n",
    "rmse(np.array(train.rating),np.array(pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9074686816484212"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test=get_pred(U,P,test)\n",
    "rmse(np.array(test.rating),np.array(pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.983248  ,  4.04853833,  4.00810724,  3.70573411,  2.7067777 ,\n",
       "        3.31425152,  4.01361493,  3.18340813,  4.75048029,  4.04618534])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.0\n",
       "1    4.5\n",
       "2    5.0\n",
       "3    4.0\n",
       "4    3.0\n",
       "5    4.0\n",
       "6    5.0\n",
       "7    1.5\n",
       "8    4.0\n",
       "9    4.0\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.rating[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * ALS with Spark ML library \n",
    "\n",
    "Spark MLlib library for Machine Learning provides a Collaborative Filtering implementation by using Alternating Least Squares. The implementation in MLlib has these parameters:\n",
    "\n",
    "* numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).\n",
    "* rank is the number of latent factors in the model.\n",
    "* iterations is the number of iterations to run.\n",
    "* lambda specifies the regularization parameter in ALS.\n",
    "* implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\n",
    "* alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations.\n",
    "\n",
    "See documentation at https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('recommend').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(rating_path, inferSchema=True, header=True)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+--------------------+\n",
      "|summary|            userId|           movieId|            rating|           timestamp|\n",
      "+-------+------------------+------------------+------------------+--------------------+\n",
      "|  count|            100004|            100004|            100004|              100004|\n",
      "|   mean| 347.0113095476181|12548.664363425463| 3.543608255669773|1.1296390869392424E9|\n",
      "| stddev|195.16383797819535|26369.198968815268|1.0580641091070326|1.9168582602710962E8|\n",
      "|    min|                 1|                 1|               0.5|           789652009|\n",
      "|    max|               671|            163949|               5.0|          1476640644|\n",
      "+-------+------------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count, mean, std, min & max\n",
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split dataset to train and test\n",
    "train, test = data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=10, regParam=0.1, nonnegative=True, coldStartStrategy=\"drop\",\\\n",
    "          userCol='userId', itemCol='movieId', ratingCol='rating')\n",
    "\n",
    "als.setSeed(23)\n",
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorized user matrix with rank = 10\n",
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "| 10|[0.5513963, 0.143...|\n",
      "| 20|[0.0, 1.1222926, ...|\n",
      "| 30|[0.38053095, 0.59...|\n",
      "| 40|[0.73925835, 0.71...|\n",
      "| 50|[0.26130113, 0.55...|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "----------------------------------------\n",
      "Factorized item matrix with rank = 10\n",
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "| 10|[0.35288718, 0.44...|\n",
      "| 20|[0.288, 0.9096849...|\n",
      "| 30|[0.92679757, 0.73...|\n",
      "| 40|[0.0, 0.5933677, ...|\n",
      "| 50|[0.77746767, 0.39...|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Factorized user matrix with rank = %d' % model.rank)\n",
    "model.userFactors.show(5)\n",
    "\n",
    "print('-'*40)\n",
    "\n",
    "print('Factorized item matrix with rank = %d' % model.rank)\n",
    "model.itemFactors.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended top users (e.g. 1 top user) for all items with the corresponding predicted ratings:\n",
      "+-------+------------------+\n",
      "|movieId|   recommendations|\n",
      "+-------+------------------+\n",
      "|   1580|  [[113, 5.10162]]|\n",
      "|   5300| [[296, 5.328037]]|\n",
      "|   6620|[[156, 4.9422774]]|\n",
      "|   7340|[[123, 4.4566317]]|\n",
      "|  32460|  [[46, 5.062686]]|\n",
      "+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Recommended top items (e.g. 1 top item) for all users with the corresponding predicted ratings:\n",
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471| [[59684, 5.028317]]|\n",
      "|   463|[[67504, 5.3299212]]|\n",
      "|   496| [[59684, 5.268713]]|\n",
      "|   148|[[67504, 5.5336957]]|\n",
      "|   540| [[59684, 5.393605]]|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Recommended top users (e.g. 1 top user) for all items with the corresponding predicted ratings:')\n",
    "model.recommendForAllItems(1).show(5)\n",
    "\n",
    "print('-'*90)\n",
    "\n",
    "print('Recommended top items (e.g. 1 top item) for all users with the corresponding predicted ratings:')\n",
    "model.recommendForAllUsers(1).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|   588|    471|   3.0| 842298526| 3.6431274|\n",
      "|    86|    471|   4.0| 848161161| 3.9828506|\n",
      "|    19|    471|   3.0| 855192558| 3.9977357|\n",
      "|    92|    471|   4.0| 848526594|  3.742887|\n",
      "|   607|    471|   4.0|1118247731| 3.8046055|\n",
      "|   358|    471|   5.0| 957479605|  3.457286|\n",
      "|   659|    471|   4.0| 853412972| 3.6239324|\n",
      "|    73|    471|   4.0|1296460183| 3.8612459|\n",
      "|   508|    471|   4.0| 844377075|  4.222822|\n",
      "|   399|    471|   5.0| 841562601| 3.0694127|\n",
      "|   296|    833|   4.5|1298158960| 1.9851413|\n",
      "|   516|   1088|   3.0| 844688144|  3.689806|\n",
      "|   372|   1088|   4.0| 958004568| 4.1652355|\n",
      "|    52|   1088|   4.0|1231766626|  4.020903|\n",
      "|   363|   1088|   2.0| 942345287| 3.5498774|\n",
      "|   582|   1088|   3.5|1122169870| 3.5549753|\n",
      "|   306|   1088|   4.0| 939760516| 3.7026877|\n",
      "|    54|   1088|   5.0|1352836913| 3.1626437|\n",
      "|   262|   1088|   2.0|1433938031| 1.8759497|\n",
      "|   564|   1088|   2.0| 974844186| 3.3114223|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.transform(test)\n",
    "pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions using RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error of the test_data: 0.9109\n"
     ]
    }
   ],
   "source": [
    "# Create an RMSE evaluator using the label and predicted columns\n",
    "evaluator = RegressionEvaluator(metricName='rmse', predictionCol='prediction', labelCol='rating')\n",
    "rmse = evaluator.evaluate(pred)\n",
    "print('Root mean squared error of the test_data: %.4f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|    23|      1|   3.0|1148729853|\n",
      "|    23|     11|   3.5|1166728170|\n",
      "|    23|     16|   4.0|1148672550|\n",
      "|    23|     19|   2.0|1148669114|\n",
      "|    23|     20|   1.5|1148720884|\n",
      "|    23|     24|   3.5|1148673467|\n",
      "|    23|     32|   4.0|1148730400|\n",
      "|    23|     47|   4.5|1148669590|\n",
      "|    23|     58|   3.5|1148672099|\n",
      "|    23|     89|   4.0|1148669357|\n",
      "|    23|    104|   3.5|1148730116|\n",
      "|    23|    110|   3.5|1148669588|\n",
      "|    23|    150|   3.5|1148672933|\n",
      "|    23|    153|   3.0|1148720873|\n",
      "|    23|    154|   4.0|1148672842|\n",
      "|    23|    172|   2.5|1148386188|\n",
      "|    23|    185|   3.5|1148778581|\n",
      "|    23|    224|   4.0|1148729797|\n",
      "|    23|    235|   4.0|1148729698|\n",
      "|    23|    236|   4.5|1148386155|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see historical rating of the user\n",
    "user_history = train.filter(train['userId']==23)\n",
    "user_history.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|movieId|userId|\n",
      "+-------+------+\n",
      "|      6|    23|\n",
      "|     34|    23|\n",
      "|     50|    23|\n",
      "|     62|    23|\n",
      "|    111|    23|\n",
      "|    307|    23|\n",
      "|    337|    23|\n",
      "|    480|    23|\n",
      "|    527|    23|\n",
      "|    541|    23|\n",
      "|    590|    23|\n",
      "|    668|    23|\n",
      "|    841|    23|\n",
      "|    900|    23|\n",
      "|    911|    23|\n",
      "|    926|    23|\n",
      "|    933|    23|\n",
      "|    969|    23|\n",
      "|   1035|    23|\n",
      "|   1077|    23|\n",
      "+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a list of movies we are thinking to offer\n",
    "user_suggest = test.filter(train['userId']==23).select(['movieId', 'userId'])\n",
    "user_suggest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|movieId|userId|prediction|\n",
      "+-------+------+----------+\n",
      "|    527|    23|  4.400507|\n",
      "|    969|    23|  4.394819|\n",
      "|  42418|    23| 4.3877387|\n",
      "|     50|    23|  4.310225|\n",
      "|   1254|    23|  4.305702|\n",
      "|    111|    23| 4.2834864|\n",
      "|   6787|    23|  4.281431|\n",
      "|   3871|    23| 4.2510843|\n",
      "|    926|    23|  4.239252|\n",
      "|   1263|    23|  4.233564|\n",
      "|   1931|    23| 4.2314863|\n",
      "|   2858|    23|  4.192382|\n",
      "|   1208|    23| 4.1598825|\n",
      "|   8239|    23|  4.158046|\n",
      "|   2068|    23| 4.1487956|\n",
      "|   4878|    23| 4.1448298|\n",
      "|   1288|    23| 4.1291714|\n",
      "|    541|    23|  4.121001|\n",
      "|   4993|    23|  4.120278|\n",
      "|   1077|    23|  4.088746|\n",
      "+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# offer movies with a high predicted rating\n",
    "user_offer = model.transform(user_suggest)\n",
    "user_offer.orderBy('prediction', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf\n",
    "* https://www.coursera.org/lecture/matrix-factorization/\n",
    "* http://www.awesomestats.in/spark-movie-recommendations/\n",
    "* https://stanford.edu/~rezab/classes/cme323/S15/notes/lec14.pdf\n",
    "* https://datasciencemadesimpler.wordpress.com/tag/alternating-least-squares/\n",
    "* https://stanford.edu/~rezab/classes/cme323/S16/projects_reports/parthasarathy_tea.pdf\n",
    "* https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/recommendation/ALS.scala\n",
    "* http://yifanhu.net/PUB/cf.pdf\n",
    "* https://github.com/bdanalytics/Berkeley-Spark/blob/master/CS110x/cs110_lab2_als_prediction.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
